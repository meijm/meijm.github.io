I"¡<p>If you run tensorflow related programs on public gpu server with jupyter-notebook. After your network is trained, tensor data may still occupy a large amount of gpu memory(you can use â€˜nvidia-smiâ€™ command to check usage of gpu). Under these circumstances, GPUs are not computing at all, but other students canâ€™t employ these Idle GPU.
<img src="/source/outofme.png" alt="out" />
Here is a easiest solution:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>
<span class="n">cuda</span><span class="p">.</span><span class="n">select_device</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cuda</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>
:ET